{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train\n",
    "### 1. 데이터 처음 학습하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. `python src/KoBART/train.py` 실행\n",
    "\n",
    "\n",
    "2. 입력값   \n",
    "    - **train_file**   \n",
    "    `train 데이터 주소` 입력\n",
    "    - **test_file**   \n",
    "    `test 데이터 주소` 입력\n",
    "    - **mode**  \n",
    "    `train` 입력\n",
    "    - **batch_size**   \n",
    "    `batch size` (ex.16) 입력  \n",
    "    auto_scale_batch_size='power' 등을 설정하더라도 임의의 값을 입력해야 함\n",
    "    - **num_workers**  \n",
    "    `num_workers` (ex.10) 입력   \n",
    "    가상 cpu 코어 개수 : 72  \n",
    "    물리적 코어 개수 = 가상 cpu 코어 개수의 절반 = 36   \n",
    "    적절한 num workers = 물리적 코어 개수의 절반 = 18  \n",
    "    num workers 18로 진행시 -> Bus error (out of shared memory) -> 도커의 shared memory 변경하면 오류 해결 가능할 것으로 예상\n",
    "    - **gradient_clip_val**   \n",
    "    `default 값`인 1.0 입력    \n",
    "    - **gpus**   \n",
    "    `제공되는 gpu의 개수` (ex.2) 인 입력\n",
    "    - **accelerator**   \n",
    "    multi gpu 사용이므로`ddp` 입력  \n",
    "    - **max_epochs**  \n",
    "    `최대 epoch 수` (ex.50) 입력\n",
    "    - **default_root_dir**  \n",
    "    `학습 결과를 저장할 폴더 경로` 입력\n",
    "    \n",
    "    \n",
    "3. 저장된 학습 결과 확인  \n",
    "    **default_root_dir** 폴더 안에 생성되는 폴더 및 파일들\n",
    "    - **kobart_summary-model_chp**   \n",
    "        : `epoch=xx-val_loss=x.xxx.ckpt` 의 형태로 체크포인트 파일 생성\n",
    "    - **tb_logs > default**   \n",
    "        : `version_x` 의 형태로 버전 폴더 생성   \n",
    "        : 버전 폴더 안 `events.out.tfevents.xxxxxxxxxxxx`, `hparams.yaml` 의 형태로 이벤트 파일과 하이퍼파라미터 파일 생성\n",
    "    - **kobart_summary-last.ckpt**   \n",
    "        : 가장 마지막 체크포인트 파일 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래 accelerator 옵션을\n",
    "mac os -> mps\n",
    "cuda (nvidia) --> gpu\n",
    "그래픽 카드 없으면 --> cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/simmin-a/Desktop/project/newj/.venv/lib/python3.9/site-packages/transformers/utils/generic.py:260: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "/Users/simmin-a/Desktop/project/newj/.venv/lib/python3.9/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n",
      "\u001b[32m2024-08-18 23:36:40.746\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m83\u001b[0m - \u001b[1mNamespace(train_file='rsc/1.Training/news_summaries.csv', test_file='rsc/2.Validation/news_summaries.csv', batch_size=4, checkpoint='checkpoint', max_len=512, max_epochs=3, lr=3e-05, accelerator='mps', num_gpus=1, gradient_clip_val=1.0, mode='train', default_root_dir='rsc/By_domain_ckpt/aihub', num_workers=2)\u001b[0m\n",
      "/Users/simmin-a/Desktop/project/newj/.venv/lib/python3.9/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n",
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: ^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/simmin-a/Desktop/project/newj/src/KoBART/train.py\", line 102, in <module>\n",
      "    wandb_logger = WandbLogger(project=\"KoBART-summ\")\n",
      "  File \"/Users/simmin-a/Desktop/project/newj/.venv/lib/python3.9/site-packages/lightning/pytorch/loggers/wandb.py\", line 360, in __init__\n",
      "    _ = self.experiment\n",
      "  File \"/Users/simmin-a/Desktop/project/newj/.venv/lib/python3.9/site-packages/lightning/fabric/loggers/logger.py\", line 118, in experiment\n",
      "    return fn(self)\n",
      "  File \"/Users/simmin-a/Desktop/project/newj/.venv/lib/python3.9/site-packages/lightning/pytorch/loggers/wandb.py\", line 408, in experiment\n",
      "    self._experiment = wandb.init(**self._wandb_init)\n",
      "  File \"/Users/simmin-a/Desktop/project/newj/.venv/lib/python3.9/site-packages/wandb/sdk/wandb_init.py\", line 1187, in init\n",
      "    raise e\n",
      "  File \"/Users/simmin-a/Desktop/project/newj/.venv/lib/python3.9/site-packages/wandb/sdk/wandb_init.py\", line 1160, in init\n",
      "    wi.setup(kwargs)\n",
      "  File \"/Users/simmin-a/Desktop/project/newj/.venv/lib/python3.9/site-packages/wandb/sdk/wandb_init.py\", line 306, in setup\n",
      "    wandb_login._login(\n",
      "  File \"/Users/simmin-a/Desktop/project/newj/.venv/lib/python3.9/site-packages/wandb/sdk/wandb_login.py\", line 298, in _login\n",
      "    wlogin.prompt_api_key()\n",
      "  File \"/Users/simmin-a/Desktop/project/newj/.venv/lib/python3.9/site-packages/wandb/sdk/wandb_login.py\", line 221, in prompt_api_key\n",
      "    key, status = self._prompt_api_key()\n",
      "  File \"/Users/simmin-a/Desktop/project/newj/.venv/lib/python3.9/site-packages/wandb/sdk/wandb_login.py\", line 201, in _prompt_api_key\n",
      "    key = apikey.prompt_api_key(\n",
      "  File \"/Users/simmin-a/Desktop/project/newj/.venv/lib/python3.9/site-packages/wandb/sdk/lib/apikey.py\", line 107, in prompt_api_key\n",
      "    result = prompt_choices(\n",
      "  File \"/Users/simmin-a/Desktop/project/newj/.venv/lib/python3.9/site-packages/wandb/util.py\", line 1256, in prompt_choices\n",
      "    choice = _prompt_choice(input_timeout=input_timeout, jupyter=jupyter)\n",
      "  File \"/Users/simmin-a/Desktop/project/newj/.venv/lib/python3.9/site-packages/wandb/util.py\", line 1239, in _prompt_choice\n",
      "    choice = input_fn(text)\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/simmin-a/Desktop/project/newj/src/KoBART/train.py\", line 102, in <module>\n",
      "    wandb_logger = WandbLogger(project=\"KoBART-summ\")\n",
      "  File \"/Users/simmin-a/Desktop/project/newj/.venv/lib/python3.9/site-packages/lightning/pytorch/loggers/wandb.py\", line 360, in __init__\n",
      "    _ = self.experiment\n",
      "  File \"/Users/simmin-a/Desktop/project/newj/.venv/lib/python3.9/site-packages/lightning/fabric/loggers/logger.py\", line 118, in experiment\n",
      "    return fn(self)\n",
      "  File \"/Users/simmin-a/Desktop/project/newj/.venv/lib/python3.9/site-packages/lightning/pytorch/loggers/wandb.py\", line 408, in experiment\n",
      "    self._experiment = wandb.init(**self._wandb_init)\n",
      "  File \"/Users/simmin-a/Desktop/project/newj/.venv/lib/python3.9/site-packages/wandb/sdk/wandb_init.py\", line 1187, in init\n",
      "    raise e\n",
      "  File \"/Users/simmin-a/Desktop/project/newj/.venv/lib/python3.9/site-packages/wandb/sdk/wandb_init.py\", line 1160, in init\n",
      "    wi.setup(kwargs)\n",
      "  File \"/Users/simmin-a/Desktop/project/newj/.venv/lib/python3.9/site-packages/wandb/sdk/wandb_init.py\", line 306, in setup\n",
      "    wandb_login._login(\n",
      "  File \"/Users/simmin-a/Desktop/project/newj/.venv/lib/python3.9/site-packages/wandb/sdk/wandb_login.py\", line 298, in _login\n",
      "    wlogin.prompt_api_key()\n",
      "  File \"/Users/simmin-a/Desktop/project/newj/.venv/lib/python3.9/site-packages/wandb/sdk/wandb_login.py\", line 221, in prompt_api_key\n",
      "    key, status = self._prompt_api_key()\n",
      "  File \"/Users/simmin-a/Desktop/project/newj/.venv/lib/python3.9/site-packages/wandb/sdk/wandb_login.py\", line 201, in _prompt_api_key\n",
      "    key = apikey.prompt_api_key(\n",
      "  File \"/Users/simmin-a/Desktop/project/newj/.venv/lib/python3.9/site-packages/wandb/sdk/lib/apikey.py\", line 107, in prompt_api_key\n",
      "    result = prompt_choices(\n",
      "  File \"/Users/simmin-a/Desktop/project/newj/.venv/lib/python3.9/site-packages/wandb/util.py\", line 1256, in prompt_choices\n",
      "    choice = _prompt_choice(input_timeout=input_timeout, jupyter=jupyter)\n",
      "  File \"/Users/simmin-a/Desktop/project/newj/.venv/lib/python3.9/site-packages/wandb/util.py\", line 1239, in _prompt_choice\n",
      "    choice = input_fn(text)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python src/KoBART/train.py \\\n",
    "--train_file='rsc/1.Training/news_summaries.csv' \\\n",
    "--test_file='rsc/2.Validation/news_summaries.csv' \\\n",
    "--mode='train' \\\n",
    "--batch_size=8 \\\n",
    "--num_workers=8 \\\n",
    "--gradient_clip_val=1.0 \\\n",
    "--accelerator='mps' \\\n",
    "--max_epochs=50 \\\n",
    "--default_root_dir='rsc/By_domain_ckpt/aihub'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 데이터 이어 학습하기 (체크포인트 이어 학습)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. `python src/KoBART/train.py` 실행\n",
    "\n",
    "\n",
    "2. 입력값\n",
    "    - **checkpoint_path**    \n",
    "    학습한 모델의 체크포인트 중 val_loss 가 가장 낮은 `체크포인트 파일 경로` 입력\n",
    "    - **hparams_file**   \n",
    "    학습한 모델의 `하이퍼파라미터 파일 경로` 입력\n",
    "    - 나머지는 위와 동일\n",
    "    \n",
    "    \n",
    "3. 저장된 학습 결과 확인   \n",
    "    위와 동일 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python src/KoBART/train.py \\\n",
    "--train_file='rsc/1.Training/news_summaries.csv' \\\n",
    "--test_file='rsc/2.Validation/news_summaries.csv' \\\n",
    "--checkpoint_path='checkpoint/model_chp/epoch=01-val_loss=1.660.ckpt' \\\n",
    "--hparams_file='rsc/By_domain_ckpt/dacon신문기사/tb_logs/default/version_1/hparams.yaml' \\\n",
    "--mode='train' \\\n",
    "--batch_size=8 \\\n",
    "--num_workers=8 \\\n",
    "--gradient_clip_val=1.0 \\\n",
    "--accelerator=mps \\\n",
    "--max_epochs=50 \\\n",
    "--default_root_dir='rsc/By_domain_ckpt/aihub'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test\n",
    "### 학습한 모델로 테스트하기 & rouge 값 출력하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. `python src/KoBART/train.py` 실행\n",
    "\n",
    "\n",
    "2. 입력값   \n",
    "    - **test_file**   \n",
    "    `test 데이터 주소` 입력\n",
    "    - **mode**  \n",
    "    `test` 입력\n",
    "    - **checkpoint_path**    \n",
    "    학습한 모델의 체크포인트 중 val_loss 가 가장 낮은 `체크포인트 파일 경로` 입력\n",
    "    - **hparams_file**   \n",
    "    학습한 모델의 `하이퍼파라미터 파일 경로` 입력\n",
    "    - **default_root_dir**  \n",
    "    `test 결과를 저장할 폴더 경로` 입력\n",
    "    - 나머지는 위와 동일\n",
    "    \n",
    "    \n",
    "3. 저장된 테스트 결과 확인  \n",
    "    **default_root_dir** 폴더 안에 생성되는 폴더 및 파일들\n",
    "    - **rouge_score.csv**     \n",
    "        : csv 형태로 rouge score가 출력된 파일 생성\n",
    "    - **tb_logs > default**   \n",
    "        : `version_x` 의 형태로 버전 폴더 생성   \n",
    "        : 버전 폴더 안 `events.out.tfevents.xxxxxxxxxxxx`, `hparams.yaml` 의 형태로 이벤트 파일과 하이퍼파라미터 파일 생성\n",
    "    - 이 외 파일은 생성되지 않음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:Namespace(accelerator='ddp', accumulate_grad_batches=1, amp_backend='native', amp_level='O2', auto_lr_find=False, auto_scale_batch_size=False, auto_select_gpus=False, automatic_optimization=None, batch_size=16, benchmark=False, check_val_every_n_epoch=1, checkpoint_callback=True, checkpoint_path='rsc/KoBART-Dacon/batch_4/not_lr_finder/num_workers4/kobart_summary-model_chp/epoch=02-val_loss=1.358.ckpt', default_root_dir='rsc/KoBART-test', deterministic=False, distributed_backend=None, enable_pl_optimizer=True, fast_dev_run=False, flush_logs_every_n_steps=100, gpus=2, gradient_clip_val=0, hparams_file='rsc/KoBART-Dacon/batch_4/not_lr_finder/num_workers4/tb_logs/default/version_0/hparams.yaml', limit_test_batches=1.0, limit_train_batches=1.0, limit_val_batches=1.0, log_every_n_steps=50, log_gpu_memory=None, logger=True, lr=3e-05, max_epochs=1000, max_len=512, max_steps=None, min_epochs=1, min_steps=None, mode='test', model_path=None, move_metrics_to_cpu=False, num_nodes=1, num_processes=1, num_sanity_val_steps=2, num_workers=10, overfit_batches=0.0, plugins=None, precision=32, prepare_data_per_node=True, process_position=0, profiler=None, progress_bar_refresh_rate=1, reload_dataloaders_every_epoch=False, replace_sampler_ddp=True, resume_from_checkpoint=None, sync_batchnorm=False, terminate_on_nan=False, test_file='rsc/data/Validation/Dacon/dev_v1.csv', tpu_cores=<function _gpus_arg_default at 0x7efd3bf732f0>, track_grad_norm=-1, train_file='rsc/data/Training/Dacon/train_v1.csv', truncated_bptt_steps=None, val_check_interval=1.0, warmup_ratio=0.1, weights_save_path=None, weights_summary='top')\n",
      "using cached model\n",
      "GPU available: True, used: True\n",
      "INFO:lightning:GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "INFO:lightning:TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "INFO:lightning:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "using cached model\n",
      "using cached model\n",
      "INFO:root:Namespace(accelerator='ddp', accumulate_grad_batches=1, amp_backend='native', amp_level='O2', auto_lr_find=False, auto_scale_batch_size=False, auto_select_gpus=False, automatic_optimization=None, batch_size=16, benchmark=False, check_val_every_n_epoch=1, checkpoint_callback=True, checkpoint_path='rsc/KoBART-Dacon/batch_4/not_lr_finder/num_workers4/kobart_summary-model_chp/epoch=02-val_loss=1.358.ckpt', default_root_dir='rsc/KoBART-test', deterministic=False, distributed_backend=None, enable_pl_optimizer=True, fast_dev_run=False, flush_logs_every_n_steps=100, gpus=2, gradient_clip_val=0, hparams_file='rsc/KoBART-Dacon/batch_4/not_lr_finder/num_workers4/tb_logs/default/version_0/hparams.yaml', limit_test_batches=1.0, limit_train_batches=1.0, limit_val_batches=1.0, log_every_n_steps=50, log_gpu_memory=None, logger=True, lr=3e-05, max_epochs=1000, max_len=512, max_steps=None, min_epochs=1, min_steps=None, mode='test', model_path=None, move_metrics_to_cpu=False, num_nodes=1, num_processes=1, num_sanity_val_steps=2, num_workers=10, overfit_batches=0.0, plugins=None, precision=32, prepare_data_per_node=True, process_position=0, profiler=None, progress_bar_refresh_rate=1, reload_dataloaders_every_epoch=False, replace_sampler_ddp=True, resume_from_checkpoint=None, sync_batchnorm=False, terminate_on_nan=False, test_file='rsc/data/Validation/Dacon/dev_v1.csv', tpu_cores=<function _gpus_arg_default at 0x7f01d32501e0>, track_grad_norm=-1, train_file='rsc/data/Training/Dacon/train_v1.csv', truncated_bptt_steps=None, val_check_interval=1.0, warmup_ratio=0.1, weights_save_path=None, weights_summary='top')\n",
      "using cached model\n",
      "LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "INFO:lightning:LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "using cached model\n",
      "initializing ddp: GLOBAL_RANK: 0, MEMBER: 1/2\n",
      "INFO:lightning:initializing ddp: GLOBAL_RANK: 0, MEMBER: 1/2\n",
      "using cached model\n",
      "initializing ddp: GLOBAL_RANK: 1, MEMBER: 2/2\n",
      "INFO:lightning:initializing ddp: GLOBAL_RANK: 1, MEMBER: 2/2\n",
      "2021-08-31 01:13:55.884760: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "Testing: 0it [00:00, ?it/s]2021-08-31 01:13:59.451443: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "Testing:   1%|▌                                 | 4/268 [00:07<07:48,  1.78s/it]^C\n"
     ]
    }
   ],
   "source": [
    "!python src/KoBART/train.py \\\n",
    "--train_file='rsc/1.Training/news_summaries.csv' \\\n",
    "--test_file='rsc/2.Validation/news_summaries.csv' \\\n",
    "--mode='test' \\\n",
    "--checkpoint_path='checkpoint/last.ckpt' \\\n",
    "--batch_size=8 \\\n",
    "--num_workers=8 \\\n",
    "--accelerator=mps \\\n",
    "--default_root_dir='rsc/By_hpram_ckpt/batch_4/not_lr_finder/test_dacon'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: python\n"
     ]
    }
   ],
   "source": [
    "!python src/KoBART/download_binary.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
